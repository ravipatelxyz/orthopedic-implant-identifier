{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for some of unet code which was adapted into this notebook: https://github.com/zhixuhao/unet\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import skimage.io as io\n",
    "from skimage.io import imshow, imread\n",
    "import skimage.transform as trans\n",
    "from skimage.transform import rotate, resize\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint, choice\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History\n",
    "from keras import backend as keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "EXPERIMENT_ID = \"01\"\n",
    "BATCHSIZE_TRAIN = 8 # batch size of 8 used in our publication\n",
    "BATCHSIZE_TEST = 1 \n",
    "THRESHOLD = 0.5\n",
    "NUM_EPOCHS = 55\n",
    "\n",
    "# directories\n",
    "INPUT_DIR = \"\" # directory containing images and masks for training / testing Unet\n",
    "SAVE_DIR = \"\" # directory for saving Unet-predicted image masks for test dataset, and other output files\n",
    "\n",
    "# load dataframes from train test splitting Excel file (update file path accordingly)\n",
    "TRAIN_DF = pd.read_excel(\"Unet_train_test.xlsx\", sheet_name=\"training\", dtype=str) \n",
    "TEST_DF = pd.read_excel(\"Unet_train_test.xlsx\", sheet_name=\"test\", dtype=str)\n",
    "\n",
    "os.chdir(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting Keras for unet segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "def adjustData(img,mask,num_class):\n",
    "    img = img / 255\n",
    "    mask = mask /255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "def rand_contrast_gradient (img):\n",
    "    image = img\n",
    "    if image.ndim == 2:\n",
    "        height, width = image.shape\n",
    "        gradient = np.ones((height, width))\n",
    "    if image.ndim == 3:\n",
    "        height, width, depth = image.shape\n",
    "        gradient = np.ones((height, width, depth))\n",
    "        \n",
    "    random_grad = choice([1.2, 1.3, 1.5, 2, 4, 5, 10, 20, 500, 500, 500, 500, 500])\n",
    "    for i in range(height*2):\n",
    "        gradient[i:] -= 1/(height*random_grad)\n",
    "        \n",
    "    random_angle = randint(0,360)\n",
    "    gradient = rotate(gradient, random_angle, resize=False, mode='edge')\n",
    "    \n",
    "    modified_image = (image*gradient).astype('float32')\n",
    "    return (modified_image)\n",
    "\n",
    "def theGenerator(batch_size,dataframe,directory,aug_dict_image,aug_dict_mask,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix = \"image\",mask_save_prefix = \"mask\",\n",
    "                    num_class = 2,save_to_dir = None,target_size = (512,512),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict_image)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict_mask)\n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = directory,\n",
    "        x_col = 'filenames',\n",
    "        y_col = None,\n",
    "        classes = None,\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = directory,\n",
    "        x_col = 'filenames',\n",
    "        y_col = None,\n",
    "        classes = None,\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    the_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in the_generator:\n",
    "        img,mask = adjustData(img,mask,num_class)\n",
    "        yield (img,mask)\n",
    "\n",
    "def saveResult(dataframe,directory,npyfile,x_col = 'filenames', num_class = 2):\n",
    "    test_image_filenames = dataframe[x_col]\n",
    "    for filename, npimage in zip(test_image_filenames, npyfile):\n",
    "        img = npimage[:,:,0]\n",
    "        img_thresh = (img > THRESHOLD).astype(np.float32)\n",
    "        io.imsave(os.path.join(directory,f\"{filename}_PRED_THRESH.png\"), img_thresh)\n",
    "\n",
    "# Two functions below are from: https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2#--responses        \n",
    "        \n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_ = tf.dtypes.cast(y_true, tf.int32)\n",
    "    y_pred_ = tf.dtypes.cast(y_pred > 0.5, tf.int32)\n",
    "    intersection = K.sum(K.abs(y_true_ * y_pred_), axis=[1,2,3])\n",
    "    union = K.sum(y_true_, [1,2,3]) + K.sum(y_pred_, [1,2,3]) - intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_ = tf.dtypes.cast(y_true, tf.int32)\n",
    "    y_pred_ = tf.dtypes.cast(y_pred > 0.5, tf.int32)\n",
    "    intersection = K.sum(y_true_ * y_pred_, axis=[1,2,3])\n",
    "    union = K.sum(y_true_, [1,2,3]) + K.sum(y_pred_, [1,2,3])\n",
    "    dice = K.mean((2 * intersection + smooth) / (union + smooth), axis=0)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#if you don't want to do data augmentation, set data_gen_args as an empty dict. e.g. data_gen_args = dict()\n",
    "\n",
    "train_data_gen_args_image = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest',\n",
    "                    preprocessing_function = rand_contrast_gradient)\n",
    "\n",
    "train_data_gen_args_mask = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_data_gen_args_image = dict()\n",
    "test_data_gen_args_mask = dict()\n",
    "\n",
    "myGeneTrain = theGenerator(BATCHSIZE_TRAIN, TRAIN_DF, INPUT_DIR, train_data_gen_args_image, train_data_gen_args_mask)\n",
    "myGeneTest = theGenerator(BATCHSIZE_TEST, TEST_DF, INPUT_DIR, test_data_gen_args_image, test_data_gen_args_mask)\n",
    "\n",
    "STEP_SIZE_TRAIN=len(TRAIN_DF.index)//BATCHSIZE_TRAIN\n",
    "STEP_SIZE_TEST=len(TEST_DF.index)//BATCHSIZE_TEST\n",
    "\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy', iou_coef, dice_coef])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "mc = ModelCheckpoint(f\"{SAVE_DIR}/unet_implant_{EXPERIMENT_ID}_BESTIOU.hdf5\", \n",
    "                                   monitor='iou_coef',\n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True, \n",
    "                                   mode='max')\n",
    "mc2 = ModelCheckpoint(f\"{SAVE_DIR}/unet_implant_{EXPERIMENT_ID}_FINALEPOCH.hdf5\", \n",
    "                     monitor=save_best_metric, mode='auto', verbose=1, save_best_only=False, period=5)   # to save last epoch\n",
    "history = model.fit_generator(generator=myGeneTrain,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=myGeneTest,\n",
    "                              validation_steps=STEP_SIZE_TEST,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              callbacks=[mc, mc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy values\n",
    "plt.plot(history.history['accuracy'], color='k', linestyle='-')\n",
    "plt.plot(history.history['val_accuracy'], color='r', linestyle='-')\n",
    "plt.title('Model accuracy',  color='k')\n",
    "plt.ylabel('Accuracy',  color='k')\n",
    "plt.xlabel('Epoch',  color='k')\n",
    "plt.legend(['Training', 'Test'], loc='upper left')\n",
    "plt.tick_params(colors='k')\n",
    "plt.xlim(0, NUM_EPOCHS)\n",
    "plt.ylim(top=1)\n",
    "plt.savefig(f\"{SAVE_DIR}/unet_accuracy_curve_{EXPERIMENT_ID}.png\", dpi=300, facecolor='w', edgecolor='w')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training loss values\n",
    "plt.plot(history.history['loss'], color='k', linestyle='-')\n",
    "plt.plot(history.history['val_loss'], color='r', linestyle='-')\n",
    "plt.title('Model loss', color='k')\n",
    "plt.ylabel('Loss', color='k')\n",
    "plt.xlabel('Epoch', color='k')\n",
    "plt.legend(['Training', 'Test'], loc='upper right')\n",
    "plt.tick_params(colors='k')\n",
    "plt.xlim(0, NUM_EPOCHS)\n",
    "plt.ylim(bottom=0)\n",
    "plt.savefig(f\"{SAVE_DIR}/unet_loss_curve_{EXPERIMENT_ID}.png\", dpi=300, facecolor='w', edgecolor='w')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot IOU and Dice coefficient values\n",
    "plt.plot(history.history['iou_coef'], color='k', linestyle='-')\n",
    "plt.plot(history.history['dice_coef'], color='k', linestyle='--')\n",
    "plt.plot(history.history['val_iou_coef'], color='r', linestyle='-')\n",
    "plt.plot(history.history['val_dice_coef'], color='r', linestyle='--')\n",
    "plt.title('Model intersection-over-union and Dice coefficient',  color='k')\n",
    "plt.ylabel('Coefficient value',  color='k')\n",
    "plt.xlabel('Epoch',  color='k')\n",
    "plt.legend(['Train IOU', 'Train Dice', 'Test IOU', 'Test Dice'], loc='upper left')\n",
    "plt.tick_params(colors='k')\n",
    "plt.xlim(0, NUM_EPOCHS)\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{SAVE_DIR}/unet_iou_dice_curve_{EXPERIMENT_ID}.png\", dpi=300, facecolor='w', edgecolor='w')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save test dataset unet-predicted masks and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.load_weights(f\"{SAVE_DIR}/unet_implant_{EXPERIMENT_ID}_FINALEPOCH.hdf5\")\n",
    "results = model.predict_generator(myGeneTest,STEP_SIZE_TEST,verbose=1)\n",
    "saveResult(TEST_DF, SAVE_DIR, results)\n",
    "\n",
    "# Parameter counts (source: https://stackoverflow.com/questions/45046525/how-can-i-get-the-number-of-trainable-parameters-of-a-model-in-keras)\n",
    "\n",
    "trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "print('\\nTotal params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [png for png in os.listdir(SAVE_DIR) if png[-10:]==\"THRESH.png\"]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=STEP_SIZE_TEST, ncols=1, figsize=(20,STEP_SIZE_TEST*15))\n",
    "\n",
    "for index, prediction in enumerate(predictions):\n",
    "    ds = io.imread(f\"{SAVE_DIR}/{prediction}\")\n",
    "    ax[index].imshow(ds, cmap='gray')\n",
    "    ax[index].set_title(f\"FILE: {prediction}\", fontsize=10, color='w')\n",
    "    ax[index].axis('off')\n",
    "       \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
