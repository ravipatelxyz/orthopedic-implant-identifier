{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:30.613602Z",
     "start_time": "2020-03-18T22:07:13.114725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Source for some of unet code which was adapted into this notebook: https://github.com/zhixuhao/unet\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from skimage.transform import resize\n",
    "from skimage import morphology, measure, draw, io, exposure\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:31.808529Z",
     "start_time": "2020-03-18T22:07:30.625529Z"
    }
   },
   "outputs": [],
   "source": [
    "UNET_WEIGHTS_VERSION = \"01\" # weight version as per hdf5 filename of desired unet\n",
    "\n",
    "# Directories\n",
    "INPUT_DIR = \"\" # directory containing entire dataset of radiographs (not just those for unet training/testing)\n",
    "SAVE_DIR = \"\" # directory to save output segmented images in and other outputs\n",
    "## load dataframes from an Excel file listing all radiographs in column 1 \"filenames\" (column 2 = \"labels\")\n",
    "## update file path accordingly\n",
    "ALL_RADIOGRAPHS_DF = pd.read_excel(\"all_radiographs.xlsx\", dtype=str) \n",
    "os.chdir(INPUT_DIR)\n",
    "\n",
    "# Parameters\n",
    "START_INDEX = 0 # start index of radiographs you wish to process\n",
    "STOP_INDEX = len(ALL_RADIOGRAPHS_DF) # stop index of radiographs you wish to process\n",
    "THRESHOLD = 0.5 # threshold applied to unet mask predictions to generate boolean array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define for generating unet masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:31.977432Z",
     "start_time": "2020-03-18T22:07:31.817519Z"
    }
   },
   "outputs": [],
   "source": [
    "Implant = [128,128,128]\n",
    "Unlabelled = [128,0,0]\n",
    "COLOR_DICT = np.array([Implant, Unlabelled])\n",
    "\n",
    "def predGenerator(dataframe, directory, x_col='filenames', target_size = (512,512), \n",
    "                  flag_multi_class = False,as_gray = True):\n",
    "    os.chdir(directory)\n",
    "    test_image_filenames = ALL_RADIOGRAPHS_DF[x_col]\n",
    "    for test_image in test_image_filenames[START_INDEX:STOP_INDEX]:\n",
    "        img = io.imread(test_image, as_gray = as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,))\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "def processPredictions(dataframe,directory,npyfile,x_col = 'filenames',num_class = 2):\n",
    "    os.chdir(directory)\n",
    "    test_image_filenames = dataframe[x_col]\n",
    "    for filename, npimage in zip(tqdm(test_image_filenames[START_INDEX:STOP_INDEX]), \n",
    "                                 npyfile):\n",
    "        # read in radiograph as numpy array\n",
    "        original_xray = io.imread(f\"{INPUT_DIR}/{filename}\")\n",
    "        target_shape = original_xray.shape\n",
    "        \n",
    "        # threshold unet generated mask\n",
    "        mask = npimage[:,:,0]\n",
    "        mask_thresh = (mask > THRESHOLD).astype(np.float64)\n",
    "        \n",
    "        # Remove small objects from mask and fill in holes\n",
    "        mask_labelled = np.array(measure.label(mask_thresh))\n",
    "        props = measure.regionprops(mask_labelled)\n",
    "        try:\n",
    "            minimum_object_size = 600\n",
    "            mask_labelled = morphology.remove_small_objects(mask_labelled.astype(np.uint16), \n",
    "                                                           min_size=minimum_object_size)\n",
    "            mask_thresh = morphology.remove_small_holes(mask_labelled.astype(np.uint16), \n",
    "                                                       area_threshold=300)\n",
    "        except:\n",
    "            print(f\"Error remove small object / small holes for file: {filename}\")\n",
    "            pass\n",
    "        \n",
    "        # mask sure mask is the same size as the radiograph\n",
    "        mask_thresh_resized = resize(mask_thresh, target_shape, anti_aliasing=False)\n",
    "        \n",
    "        # Use mask to crop implant out of radiograph, then apply adaptive histogram equilasation, and save output\n",
    "        props_new = measure.regionprops(mask_thresh_resized.astype(np.uint16))\n",
    "        try:\n",
    "            bound_box_corners = props_new[0].bbox\n",
    "            min_row, min_col, max_row, max_col = bound_box_corners\n",
    "            try:\n",
    "                img_cropped = ((original_xray*mask_thresh_resized).astype(np.uint16))[min_row-10:max_row+10,\n",
    "                                                                                     min_col-10:max_col+10]\n",
    "            except:\n",
    "                img_cropped = ((original_xray*mask_thresh_resized).astype(np.uint16))[min_row:max_row, \n",
    "                                                                                     min_col:max_col]\n",
    "            img_equalised_cropped = exposure.equalize_adapthist(img_cropped, clip_limit=0.03)\n",
    "            io.imsave(os.path.join(directory,f\"{filename[:-9]}CROP.png\"), img_equalised_cropped)       \n",
    "        except:\n",
    "            print(f\"Error producing bounding box for file: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:32.098357Z",
     "start_time": "2020-03-18T22:07:31.984421Z"
    }
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate unet predicted masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:38.219995Z",
     "start_time": "2020-03-18T22:07:32.109351Z"
    }
   },
   "outputs": [],
   "source": [
    "predGene = predGenerator(ALL_RADIOGRAPHS_DF, INPUT_DIR)\n",
    "model = unet()\n",
    "model.load_weights(f\"unet_implant_{UNET_WEIGHTS_VERSION}_FINALEPOCH.hdf5\")\n",
    "predictions = model.predict_generator(predGene,STOP_INDEX-START_INDEX,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using masks to segment radiographs, applying further final processing, and saving segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T22:07:38.256975Z",
     "start_time": "2020-03-18T22:07:13.103Z"
    }
   },
   "outputs": [],
   "source": [
    "processPredictions(ALL_RADIOGRAPHS_DF, SAVE_DIR, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
