{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:36:57.130821Z",
     "start_time": "2020-03-24T19:36:44.292533Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_UNIL = \"\" # File path to folder containing UNIL images\n",
    "DIR_CROP = \"\" # File path to folder containing CROP images\n",
    "\n",
    "# File path for Excel file containing UNIL train/val/test splitting:\n",
    "UNIL_TRAIN_VALID_TEST_EXCEL_FILEPATH = \"............/classification_training_validation_test_UNIL.xlsx\"\n",
    "# File path for Excel file containing CROP train/val/test splitting:\n",
    "CROP_TRAIN_VALID_TEST_EXCEL_FILEPATH = \"............/classification_training_validation_test_CROP.xlsx\"\n",
    "\n",
    "# File path for neural net 1 (neural net taking UNIL inputs) for ensembling\n",
    "DIR_NN1 = \"............./0001_InceptionV3_imagenet_FINALEPOCH_UNIL.h5\"\n",
    "# File path for neural net 2 (neural net taking CROP inputs) for ensembling\n",
    "DIR_NN2 = \"............./0001_Xception_imagenet_FINALEPOCH_CROP.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:36:57.839852Z",
     "start_time": "2020-03-24T19:36:57.175795Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df_unil = pd.read_excel(UNIL_TRAIN_VALID_TEST_EXCEL_FILEPATH, \n",
    "                             sheet_name=f\"TEST_DF\", dtype=str)\n",
    "test_df_crop = pd.read_excel(CROP_TRAIN_VALID_TEST_EXCEL_FILEPATH, \n",
    "                             sheet_name=f\"TEST_DF\", dtype=str)\n",
    "\n",
    "image_count = test_df_unil.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup image data generators and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:36:58.047135Z",
     "start_time": "2020-03-24T19:36:57.896821Z"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator_1 = test_datagen.flow_from_dataframe(test_df_unil, directory=DIR_UNIL, class_mode='categorical', x_col='filenames', y_col='labels',\n",
    "                                                    target_size=(299, 299), batch_size=1, shuffle=False)\n",
    "test_generator_2 = test_datagen.flow_from_dataframe(test_df_crop, directory=DIR_CROP, class_mode='categorical', x_col='filenames', y_col='labels',\n",
    "                                                    target_size=(299, 299), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:38:55.075554Z",
     "start_time": "2020-03-24T19:36:58.097499Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = load_model(DIR_NN1)\n",
    "model_2 = load_model(DIR_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate class predictions and true classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:45:53.455654Z",
     "start_time": "2020-03-24T19:42:38.080625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate numpy array of predictions (one hot encoded) for model 1 as well as array of true class labels\n",
    "output_model_1 = []\n",
    "output_true = []\n",
    "\n",
    "for i, (image, true) in enumerate(tqdm(test_generator_1)):\n",
    "    pred = model_1.predict(image)[0]\n",
    "    output_model_1.append(pred)\n",
    "    output_true.append(true)\n",
    "    if i == image_count-1:\n",
    "        break\n",
    "\n",
    "# Generate numpy array of predictions (one hot encoded) for model 2       \n",
    "output_model_2 = []\n",
    "\n",
    "for i, (image, _) in enumerate(tqdm(test_generator_2)):\n",
    "    pred = model_2.predict(image)[0]\n",
    "    output_model_2.append(pred)\n",
    "    if i == image_count-1:\n",
    "        break\n",
    "\n",
    "# Generate 1:1 weighted averages of predictions for the two models\n",
    "weighted_averages = []\n",
    "for (out1, out2) in zip(output_model_1, output_model_2):\n",
    "    weighted_average = (out1+out2)/2\n",
    "    weighted_averages.append(weighted_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy and top 3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:46:01.061313Z",
     "start_time": "2020-03-24T19:46:01.029331Z"
    }
   },
   "outputs": [],
   "source": [
    "corrects = []\n",
    "for i in range(image_count):\n",
    "    corrects.append(np.argmax(weighted_averages[i]) == np.argmax(output_true[i]))\n",
    "\n",
    "print(f\"Accuracy: {sum(corrects)/image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:46:06.017483Z",
     "start_time": "2020-03-24T19:46:05.945527Z"
    }
   },
   "outputs": [],
   "source": [
    "top_3_accuracy = []\n",
    "pred_list = []\n",
    "true_list = []\n",
    "for i in range(image_count):\n",
    "    pred = weighted_averages[i]\n",
    "    true = output_true[i]\n",
    "    top_3_pred = np.argpartition(pred, -3)[-3:]\n",
    "    if top_3_pred[0] == np.argmax(true) or top_3_pred[1] == np.argmax(true) or top_3_pred[2] == np.argmax(true):\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    top_3_accuracy.append(correct)\n",
    "    pred_list.append(np.argmax(pred))\n",
    "    true_list.append(np.argmax(true))\n",
    "    \n",
    "\n",
    "top_3_accuracy = sum(top_3_accuracy) / image_count\n",
    "print(f\"Top 3 accuracy: {top_3_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:46:12.474823Z",
     "start_time": "2020-03-24T19:46:12.447817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix numpy array\n",
    "confusion_mx = confusion_matrix(true_list,pred_list)\n",
    "\n",
    "class_indices = test_generator_1.class_indices\n",
    "\n",
    "# Then convert confusion matrix into pd dataframe with labels along column and along top\n",
    "class_indices = test_generator_1.class_indices\n",
    "confusion_matrix_df = pd.DataFrame(confusion_mx,\n",
    "                                   index = [f\"{i}_{c}_true\" for i,c in enumerate(list(class_indices.keys()))],\n",
    "                                   columns = [f\"{i}\" for i,c in enumerate(list(class_indices.keys()))])\n",
    "\n",
    "print(confusion_matrix_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
